use rayon::prelude::*;
use std::{
    simd::{num::*, *},
    sync::{Arc, LazyLock, Mutex},
};

#[derive(Clone, Copy, Debug)]
struct Sequence(u32);

impl Sequence {
    fn next(&self) -> Self {
        let mut value = self.0;

        value ^= value << u32::ilog2(64); // Multiply by 64.
        value %= 0x1_00_00_00;

        // No need to reduce after this division, since it can never make the
        // value larger than it was before.
        value ^= value >> u32::ilog2(32); // Divide by 32.

        value ^= value << u32::ilog2(2048); // Multiply by 2048.
        value %= 0x1_00_00_00;

        Sequence(value)
    }

    fn bananas(&self) -> u8 {
        (self.0 % 10) as u8
    }
}

struct Window {
    value: u32,
}

impl Window {
    const BASE: usize = 19;
    const LENGTH: usize = 4;
    const NUM_ENCODED_INDICES: usize = Self::BASE.pow(Self::LENGTH as u32);

    fn new() -> Window {
        Window { value: 0 }
    }

    /// Push a new value into the window.
    /// Returns the encoding for the window.
    fn push_and_encode(&mut self, diff: i8) -> u32 {
        // Since a difference is between -9 to 9, there's only 19 possible
        // values. Hence we can encode a 4-element window as a 32 bit value.
        // This also ensures all possible windows are encoded into a contiguous
        // range, which means we can use e.g. a Vec to map them. There's approx.
        // 130k, so no issue storage-wise (around half a MiB if storing u32).

        assert!((-9..=9).contains(&diff));
        self.value %= Self::BASE.pow((Self::LENGTH - 1) as u32) as u32; // Remove "MSB".
        self.value *= Self::BASE as u32; // Shift all "digits" one place up.
        self.value += (diff + 9) as u32;

        // NOTE: This assert doesn't affect benchmarked time.
        assert!(self.value < Self::NUM_ENCODED_INDICES as u32);

        self.value
    }
}

#[allow(dead_code)]
struct TableEntryConsts {}

impl TableEntryConsts {
    const WINDOW_IDX_BITS: u32 = Window::BASE.pow(Window::LENGTH as u32).ilog2() + 1;
    const BANANAS_BITS: u32 = 9u32.ilog2() + 1;
    const PREV_SEEN_BITS: u32 = (Tables::BIDDING_LENGTH + 1).ilog2() + 1;
}

#[allow(dead_code)]
#[derive(Debug, Clone, Copy)]
struct TableEntryPacked {
    //data: u32,
    window_and_bananas: u32,
    prev_seen: u16,
}

#[allow(dead_code)]
impl TableEntryPacked {
    fn new() -> TableEntryPacked {
        assert!(24 >= TableEntryConsts::WINDOW_IDX_BITS as usize);
        assert!(8 >= TableEntryConsts::BANANAS_BITS as usize);
        assert!(8 * std::mem::size_of::<u16>() >= TableEntryConsts::PREV_SEEN_BITS as usize);
        TableEntryPacked {
            window_and_bananas: 0,
            prev_seen: 0,
        }
    }

    /// The window index (i.e. encoded last Window::LENGTH differences in base
    /// Window::BASE).
    #[inline(always)]
    fn window_idx(&self) -> usize {
        (self.window_and_bananas & 0xFF_FF_FF) as usize
    }

    /// The number of bananas offered at the current window index.
    #[inline(always)]
    fn bananas(&self) -> u8 {
        (self.window_and_bananas >> 24) as u8
    }

    /// How many "secret iterations" ago this window index was last seen. Since
    /// we only look at Tables::BIDDING_LENGTH secrets, there's no need to be
    /// able to store a larger difference.
    #[inline(always)]
    fn prev_seen(&self) -> u32 {
        self.prev_seen as u32
    }

    fn set_window_idx(&mut self, window_idx: u32) {
        assert!(window_idx < (1u32 << TableEntryConsts::WINDOW_IDX_BITS));
        self.window_and_bananas &= !0xFF_FF_FF;
        self.window_and_bananas |= window_idx;
    }

    fn set_bananas(&mut self, bananas: u8) {
        assert!(bananas < (1u8 << TableEntryConsts::BANANAS_BITS));
        self.window_and_bananas &= 0xFF_FF_FF;
        self.window_and_bananas |= (bananas as u32) << 24;
    }

    fn set_prev_seen(&mut self, prev_seen: u32) {
        assert!(prev_seen < (1u32 << TableEntryConsts::PREV_SEEN_BITS));
        self.prev_seen = prev_seen as u16;
    }
}

/// Hand-rolled bit-packed struct, because the getters generated by the bitfield
/// crate are suboptimal.
#[allow(dead_code)]
#[derive(Debug, Clone, Copy)]
struct TableEntryExtraPacked {
    data: u32,
}

#[allow(dead_code)]
impl TableEntryExtraPacked {
    const WINDOW_IDX_MASK: u32 = ((1u64 << TableEntryConsts::WINDOW_IDX_BITS) - 1) as u32;
    const WINDOW_IDX_SHIFT: u32 = 0;

    const BANANAS_MASK: u32 = ((1u64 << TableEntryConsts::BANANAS_BITS) - 1) as u32;
    const BANANAS_SHIFT: u32 = Self::WINDOW_IDX_SHIFT + TableEntryConsts::WINDOW_IDX_BITS;

    const PREV_SEEN_MASK: u32 = ((1u64 << TableEntryConsts::PREV_SEEN_BITS) - 1) as u32;
    const PREV_SEEN_SHIFT: u32 = Self::BANANAS_SHIFT + TableEntryConsts::BANANAS_BITS;

    fn new() -> TableEntryExtraPacked {
        assert!(
            (TableEntryConsts::WINDOW_IDX_BITS
                + TableEntryConsts::BANANAS_BITS
                + TableEntryConsts::PREV_SEEN_BITS)
                <= (8 * std::mem::size_of::<u32>() as u32)
        );
        TableEntryExtraPacked { data: 0 }
    }

    /// The window index (i.e. encoded last Window::LENGTH differences in base
    /// Window::BASE).
    #[inline(always)]
    fn window_idx(&self) -> usize {
        ((self.data >> Self::WINDOW_IDX_SHIFT) & Self::WINDOW_IDX_MASK) as usize
    }

    /// The number of bananas offered at the current window index.
    #[inline(always)]
    fn bananas(&self) -> u8 {
        ((self.data >> Self::BANANAS_SHIFT) & Self::BANANAS_MASK) as u8
    }

    /// How many "secret iterations" ago this window index was last seen. Since
    /// we only look at Tables::BIDDING_LENGTH secrets, there's no need to be
    /// able to store a larger difference.
    #[inline(always)]
    fn prev_seen(&self) -> u32 {
        (self.data >> Self::PREV_SEEN_SHIFT) & Self::PREV_SEEN_MASK
    }

    fn set_window_idx(&mut self, window_idx: u32) {
        assert!(window_idx < (1u32 << TableEntryConsts::WINDOW_IDX_BITS));
        self.data &= !(Self::WINDOW_IDX_MASK << Self::WINDOW_IDX_SHIFT);
        self.data |= (window_idx & Self::WINDOW_IDX_MASK) << Self::WINDOW_IDX_SHIFT;
    }

    fn set_bananas(&mut self, bananas: u8) {
        assert!(bananas < (1u8 << TableEntryConsts::BANANAS_BITS));
        self.data &= !(Self::BANANAS_MASK << Self::BANANAS_SHIFT);
        self.data |= ((bananas as u32) & Self::BANANAS_MASK) << Self::BANANAS_SHIFT;
    }

    fn set_prev_seen(&mut self, prev_seen: u32) {
        assert!(prev_seen < (1u32 << TableEntryConsts::PREV_SEEN_BITS));
        self.data &= !(Self::PREV_SEEN_MASK << Self::PREV_SEEN_SHIFT);
        self.data |= (prev_seen & Self::PREV_SEEN_MASK) << Self::PREV_SEEN_SHIFT;
    }
}

// NOTE: The "ExtraPacked" version is approximately 5% faster than the "regular"
// packed one.
type TableEntry = TableEntryExtraPacked;

#[derive(Debug)]
struct Tables {
    // NOTE: Since the tables are so massive and we create them at runtime, they
    // must go on the heap. Hence the Box<> insted of fixed-size arrays.
    start_idx: Box<[u32]>,   // Mapping of secret to index into other tables.
    info: Box<[TableEntry]>, // Mapping of secret to related information.
    advanced_secrets: Box<[u32]>, // Each secret number, advanced 2000 times.
}

impl Tables {
    const LFSR_LENGTH: usize = (1 << 24) - 1;
    const SEQUENCE_LENGTH: usize = 2000;
    // A bidding length is slightly less than sequence length, due to the window
    // initialization that needs to happen before a set of 4 differences exists.
    const BIDDING_LENGTH: usize = Self::SEQUENCE_LENGTH - Window::LENGTH;
    // Need extra element, to use index 0 as a dummy to avoid off-by-one errors.
    const NUM_TABLE_ELEMENTS: usize = Self::LFSR_LENGTH + Self::BIDDING_LENGTH + 1;

    fn new() -> Self {
        let advanced_secrets = Self::_gen_part_a_lookup();
        let (start_idx, info) = Self::_gen_part_b_lookup();

        Tables {
            start_idx,
            info,
            advanced_secrets,
        }
    }

    fn _gen_part_a_lookup() -> Box<[u32]> {
        let time_start = std::time::Instant::now();

        // Ensure each value is a direct look-up, i.e. add a place for 0.
        let mut secrets = vec![0u32; Self::LFSR_LENGTH + 1];
        let mut secret_to_idx = vec![0u32; Self::LFSR_LENGTH + 1];

        // Generate a table with each secret value.
        let mut secret = Sequence(1);
        for idx in 1..secrets.len() {
            secret_to_idx[secret.0 as usize] = idx as u32;
            secrets[idx] = secret.0;
            secret = secret.next();
        }

        // Now rotate all values by SEQUENCE_LENGTH to map each value to the one
        // SEQUENCE_LENGTH iterations later.
        secrets[1..].rotate_left(Self::SEQUENCE_LENGTH);

        // Finally, permute all values such that e.g. the entry at index 3
        // contains the value after advancing Sequence(3) SEQUENCE_LENGTH times.
        let result: Vec<_> = secret_to_idx
            .iter()
            .map(|offset| secrets[*offset as usize])
            .collect();

        log::debug!(
            "Finished part A table generation in {:.3} ms",
            (std::time::Instant::now() - time_start).as_millis_f32()
        );

        result.into_boxed_slice()
    }

    fn _gen_part_b_lookup() -> (Box<[u32]>, Box<[TableEntry]>) {
        // NOTE: This could be generated using SIMD, but really, there's no
        // point since these tables should be considered constants. The only
        // reason they're not is because Rust's const fn functionality is pretty
        // lacking.
        let time_start = std::time::Instant::now();

        // Extra entry for maximum value.
        let mut start_idxes = vec![0u32; Self::LFSR_LENGTH + 1];
        let mut info = vec![TableEntry::new(); Self::NUM_TABLE_ELEMENTS];

        // NOTE: In order to calculate valid window index 4 secret values are
        // required. Hence we start at offset 4 in the arrays and wrap around
        // to ensure the first 3 elements are written as well.
        let mut secret = Sequence(1);
        let mut prev_bananas = secret.bananas();
        let mut window = Window::new();
        let mut window_prev_idx = vec![0u32; Window::NUM_ENCODED_INDICES];

        for _ in 0..Window::LENGTH - 1 {
            secret = secret.next();
            let bananas = secret.bananas();
            let diff: i8 = (bananas as i8) - (prev_bananas as i8);

            window.push_and_encode(diff);
            prev_bananas = bananas;
        }

        // Start index at 1, so 0 can be used as initial value for prev_seen.
        let mut idx = 1usize;
        let first_secret = secret.0;

        // For every secret value, store where its info is in the table. For
        // every info, store the associated window index, number of generated
        // bananas, and for which info the window index was last seen (i.e. how
        // many secrets ago).
        loop {
            let entry = &mut info[idx];

            secret = secret.next();
            let bananas = secret.bananas();
            let diff: i8 = (bananas as i8) - (prev_bananas as i8);
            let window_idx = window.push_and_encode(diff);
            prev_bananas = bananas;

            // Ensure index points to the table's first LFSR_LENGTH entries.
            if idx <= Self::LFSR_LENGTH {
                start_idxes[secret.0 as usize] = idx as u32;
            }

            entry.set_window_idx(window_idx);
            entry.set_bananas(bananas);

            let num_steps_ago_seen = idx as u32 - window_prev_idx[window_idx as usize];
            entry.set_prev_seen(std::cmp::min(
                num_steps_ago_seen,
                (Tables::BIDDING_LENGTH + 1) as u32,
            ));

            window_prev_idx[window_idx as usize] = idx as u32;

            if !(10..(Self::NUM_TABLE_ELEMENTS - 9)).contains(&idx) {
                log::trace!(
                    "idx: {:8}, secret: {:8}, window: {:6}, bananas: {:1}, prev_seen: {:8}",
                    idx,
                    secret.0,
                    entry.window_idx(),
                    entry.bananas(),
                    entry.prev_seen()
                );
            }

            idx += 1;

            // Ensure LFSR is maximum length (i.e. one single long cycle).
            if first_secret == secret.0 {
                assert_eq!(idx - 1, Self::LFSR_LENGTH, "Not a maximum length LFSR");
            }

            // Loop the end, to ensure prev_seen values are correct for the last
            // "duplicated" BIDDING_LENGTH elements as well.
            if idx == Self::NUM_TABLE_ELEMENTS {
                break;
            }
        }

        log::debug!(
            "Finished part B table generation in {:.3} ms",
            (std::time::Instant::now() - time_start).as_millis_f32()
        );

        (start_idxes.into_boxed_slice(), info.into_boxed_slice())
    }
}

static TABLES: LazyLock<Box<Tables>> = LazyLock::new(|| Box::new(Tables::new()));

#[derive(Debug, Clone)]
struct MarketState {
    sum: Vec<u16>,
}

impl MarketState {
    fn new() -> MarketState {
        MarketState {
            sum: vec![0; Window::NUM_ENCODED_INDICES],
        }
    }

    fn process_monkey_bidding(&mut self, table_index: usize) {
        // NOTE: Don't use an inclusive range with usize, because then Rust uses
        // a 128-bit variable to guard against overflow.
        let range = table_index..table_index + Tables::BIDDING_LENGTH;
        let infos = &TABLES.info[range];

        // SIMD doesn't seem to do much good here, due to the gather & scatter
        // required all over the place. So instead, pack all data into a single
        // word and process sequentially.
        for (info, idx) in infos.iter().zip(0u32..) {
            // If the window index was last seen more steps ago than we're into
            // the current iteration, then it's the first time we see it this
            // iteration.
            let first_occurence = info.prev_seen() > idx;

            // NOTE: First occurence is almost always true, so doing the sum
            // update unconditional is approximately 5% faster.
            *unsafe { self.sum.get_unchecked_mut(info.window_idx()) } +=
                (first_occurence as u16) * (info.bananas() as u16);
        }
    }
}

#[derive(Debug)]
struct MarketStateBuilder {
    // TODO: Does a VecDeque speed things up here?
    states: Vec<Arc<Mutex<MarketState>>>,
}

impl MarketStateBuilder {
    fn new() -> MarketStateBuilder {
        MarketStateBuilder { states: vec![] }
    }

    fn build(&mut self) -> Arc<Mutex<MarketState>> {
        let state = Arc::new(Mutex::new(MarketState::new()));
        self.states.push(state.clone());
        {
            let guard = state.lock().unwrap();
            let data: &MarketState = &guard;
            log::trace!("Build new MarketState @ {:p}", &data.sum);
        }
        state
    }
}

pub fn part_a(input: &str) -> u64 {
    // Gather all starting seeds in a Vec first, to allow chunking them up in
    // parallel afterwards.
    let seeds: Vec<u32> = input
        .lines()
        .map(|e| -> u32 { e.parse().unwrap() })
        .collect();

    // NOTE: Sorting all seeds, such that table lookups would hopefully hit more
    // of the cache, doesn't improve runtime.

    // Used to prevent rayon from spawning 1000s of jobs.
    let num_workers: usize = std::thread::available_parallelism().unwrap().get();

    const USE_SIMD: bool = true;
    const SIMD_SIZE: usize = 8; // Tiny bit faster than 4 or 16.

    match USE_SIMD {
        false => seeds
            .par_iter()
            .with_min_len(seeds.len().div_ceil(num_workers))
            .map(|secret| TABLES.advanced_secrets[*secret as usize] as u64)
            .sum(),
        true => {
            let seeds_iter = seeds.par_chunks_exact(SIMD_SIZE);

            let mut sum: u64 = seeds_iter
                .remainder()
                .iter()
                .map(|secret| TABLES.advanced_secrets[*secret as usize] as u64)
                .sum();

            sum += seeds_iter
                .with_min_len(seeds.len().div_ceil(SIMD_SIZE) / num_workers)
                .map(|chunk| {
                    let idxes = Simd::from_slice(chunk);
                    unsafe {
                        Simd::gather_select_unchecked(
                            TABLES.advanced_secrets.as_ref(),
                            Mask::splat(true),
                            idxes.cast(),
                            Simd::splat(0),
                        )
                    }
                    .cast()
                })
                .sum::<Simd<u64, SIMD_SIZE>>()
                .reduce_sum();

            sum
        }
    }
}

fn sum_states(state_builder: Mutex<MarketStateBuilder>) -> u64 {
    log::debug!("# states: {}", state_builder.lock().unwrap().states.len());

    // Reduce all the sums in the list of shared states. Also do some magic to
    // extract MarketState's "sums" from Arc<Mutex<...>>.
    let sums = Arc::try_unwrap(
        state_builder
            .into_inner() // Extract from Mutex<...>.
            .unwrap()
            .states
            .into_iter()
            .reduce(|acc, e| {
                // Sum together all the state's "sums" vectors.
                assert!(!Arc::ptr_eq(&acc, &e));
                {
                    let mut acc_guard = acc.lock().unwrap();
                    let elem_guard = e.lock().unwrap();

                    let sum_lhs = acc_guard.sum.as_mut_slice();
                    let sum_rhs = elem_guard.sum.as_slice();

                    assert_eq!(sum_lhs.len(), sum_rhs.len());
                    sum_lhs
                        .iter_mut()
                        .zip(sum_rhs)
                        .for_each(|(lhs, rhs)| *lhs += rhs);
                }
                acc
            })
            .unwrap(),
    )
    .unwrap() // Here the extraction magic continues.
    .into_inner() // Extract from the Mutex<...>.
    .unwrap()
    .sum;

    *sums.iter().max().unwrap() as u64
}

fn calculate_part_b_info_index(mut secret: Sequence) -> u32 {
    // NOTE: Don't use an inclusive range with usize, because then Rust uses
    // a 128-bit variable to guard against overflow.
    (0..Window::LENGTH).for_each(|_| secret = secret.next());
    TABLES.start_idx[secret.0 as usize]
}

pub fn part_b(input: &str) -> u64 {
    let state_builder: Mutex<MarketStateBuilder> = Mutex::new(MarketStateBuilder::new());

    let secrets: Vec<_> = input
        .lines()
        .map(|e| Sequence(e.parse().unwrap()))
        .collect();

    // NOTE: Don't split into more chunks than the number of available cores,
    // since this will just create tons of extra state that then later has to
    // be accumulated.
    let num_workers: usize = std::thread::available_parallelism().unwrap().get();

    let mut table_indices: Vec<_> = secrets
        .par_iter()
        .with_min_len(secrets.len().div_ceil(num_workers))
        .map(|secret| calculate_part_b_info_index(*secret))
        .collect();

    // Sorting this every so slightly improves runtime, because of a tiny bit
    // more cache hits.
    table_indices.sort_unstable();

    const RUN_PARALLEL: bool = true;
    match RUN_PARALLEL {
        false => {
            let state = state_builder.lock().unwrap().build();
            let mut guard = state.lock().unwrap();
            table_indices.iter().for_each(|idx| {
                guard.process_monkey_bidding(*idx as usize);
            });
        }
        true => {
            table_indices
                .par_iter()
                .with_min_len(table_indices.len().div_ceil(num_workers))
                .for_each_init(
                    // Create threat-local state using ..._init.
                    || state_builder.lock().unwrap().build(),
                    |local_state, idx| {
                        {
                            // Only one thread should be accessing this state anyway.
                            let mut guard = local_state.lock().unwrap();
                            guard.process_monkey_bidding(*idx as usize);
                        }
                    },
                );
        }
    }

    sum_states(state_builder)
}

pub fn init() {
    // Ensure tables are constructed before test. In C++ it would be trivial to
    // build these tables at compile-time. However, Rust makes it much harder,
    // and I don't feel like copy-pasting over 128 MiB of generated tables into
    // a file. So just do this instead.
    LazyLock::force(&TABLES);
}

#[cfg(test)]
mod tests {
    #[test]
    fn example_a() {
        util::run_test(|| {
            let expected: u64 = 37327623;
            assert_eq!(
                crate::day_22::part_a(&util::read_resource("example_22-part_a.txt").unwrap()),
                expected
            );
        });
    }

    #[test]
    fn example_b() {
        util::run_test(|| {
            let expected: u64 = 23;
            assert_eq!(
                crate::day_22::part_b(&util::read_resource("example_22-part_b.txt").unwrap()),
                expected
            );
        });
    }
}
